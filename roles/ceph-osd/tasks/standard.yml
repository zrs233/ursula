---
#  create ssd root bucket
- name: Create root ssd-bucket root
  shell: ceph osd crush add-bucket {{ ssd_pool }} root
  register: result
  changed_when: result.stdout |search("added bucket")
  when: inventory_hostname == groups['ceph_osds_ssd'][0]

# Create crush ruleset for the ssd root bucket
- name: Create crush ruleset ssd root bucket
  shell: ceph osd crush rule create-simple {{ ssd_ruleset }} {{ ssd_pool }} host firstn
  register: result
  changed_when: not result.stdout |search("already exists")
  when: inventory_hostname == groups['ceph_osds_ssd'][0]

# Create osd host bucket
- name: Create osd host bucket
  shell: ceph osd crush add-bucket {{ ansible_hostname }} host
  register: result
  changed_when: result.stdout |search("added bucket")

# Move the host bucket under corresponding root
- name: Move host bucket under root bucket
  shell: ceph osd crush move {{ ansible_hostname }} root={{ ssd_pool }}
  register: result
  changed_when: result.stdout |search("moved item")

# we check for a ceph partition to avoid destructive tasks below
- name: check if 'ceph' partition exists on osd disks
  shell: "parted --script /dev/{{ item }} print | egrep -sq 'ceph'"
  with_items: "{{ ceph.disks }}"
  ignore_errors: true
  changed_when: false
  register: ceph_partitions

# journal_collocation
- name: prepare osd disks
  command: ceph-disk prepare /dev/{{ item.1 }}
  with_together:
    - ceph_partitions.results
    - ceph.disks
  when: item.0.rc != 0

- name: activate osds
  command: ceph-disk activate /dev/{{ item.1 }}1
  with_together:
    - ceph_partitions.results
    - ceph.disks
  when: item.0.rc != 0

# pool pg number is based on osd amount
# we should create pool when all osds are up
- name: create openstack pool
  ceph_pool:
    pool_name: "{{ ssd_pool }}"
    osds: "{{ groups['ceph_osds_ssd']|length * ceph.disks|length }}"
  delegate_to: "{{ groups['ceph_monitors'][0] }}"
  when: inventory_hostname == groups['ceph_osds_ssd'][-1]

# not sure is there a better way to get ruleset id
- name: set ruleset for pool
  shell: ceph osd pool set {{ ssd_pool }} crush_ruleset
         $(ceph osd crush rule dump |grep {{ ssd_ruleset }} -A1 |grep -oP '\d+')
  delegate_to: "{{ groups['ceph_monitors'][0] }}"
  when: inventory_hostname == groups['ceph_osds_ssd'][-1]
